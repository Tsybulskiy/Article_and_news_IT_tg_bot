import json
from requests import get
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import time
import undetected_chromedriver as uc
import mysql.connector

headers = {
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 YaBrowser/23.1.4.778 Yowser/2.5 Safari/537.36"
    }


db = mysql.connector.connect(
                        host="127.0.0.1",
                        user="root",
                        password="12345678",
                        port="3306",
                        database="bot",
                        option_files='my.conf',
                        get_warnings=True
                    )

def insert_link_into_bd (title,link,text,date):
    cursor = db.cursor(buffered=True)
    try:
        syntext = """Insert into news (Link,Title,Text,Date) values (%s,%s,%s,%s);"""
        value = (link, title, text, date)
        cursor.execute(syntext,value)
        db.commit()
    except mysql.connector.Error as err:
        if err.sqlstate == '23000': raise err

def get_news_from_anti_malware():
    for page in range(0,2):
        resp = get(f'https://www.anti-malware.ru/news?page={page}', headers=headers)
        bs = BeautifulSoup(resp.text, 'html.parser')
        cards = bs.find_all('div', class_='node')
        for card in cards:
            title = card.find('h2').find('a').text
            link = 'https://www.anti-malware.ru' + card.find('h2').find('a').get('href')
            date_list = link.split('/')[-2].split('-')
            date = date_list[0] + '-' + date_list[1] + '-' + date_list[2]
            description = card.find('div', class_='content').find('div', class_='txt-wrap').find('p').text
            text=description
            insert_link_into_bd (title,link,text,date)
            print(title)
            print(link)
            print(date)
            print(description)
            print('--------')
        time.sleep(3)
get_news_from_anti_malware()